{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/surajpatil/miniconda3/envs/mlfetch/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model class\n",
    "class MultiTaskSentenceTransformer(nn.Module):\n",
    "    def __init__(self, model_name='sentence-transformers/all-MiniLM-L6-v2', num_classes_A=3, num_classes_B=3):\n",
    "        super(MultiTaskSentenceTransformer, self).__init__()\n",
    "        # Shared Transformer Encoder\n",
    "        self.transformer = AutoModel.from_pretrained(model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        \n",
    "        # Task A: Sentence Classification Head\n",
    "        self.classification_head_A = nn.Linear(self.transformer.config.hidden_size, num_classes_A)\n",
    "        \n",
    "        # Task B: Sentiment Analysis Head\n",
    "        self.classification_head_B = nn.Linear(self.transformer.config.hidden_size, num_classes_B)\n",
    "        \n",
    "        # Task A labels (mapping index to sentence classification label)\n",
    "        self.sentence_classification_labels = {0: 'class_1', 1: 'class_2', 2: 'class_3'}\n",
    "        \n",
    "        # Sentiment labels (mapping index to sentiment type)\n",
    "        self.sentiment_labels = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "\n",
    "    def mean_pooling(self, model_output, attention_mask):\n",
    "        \"\"\"Mean Pooling - Take attention mask into account for correct averaging.\"\"\"\n",
    "        token_embeddings = model_output[0]  # First element is the hidden states\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        return sum_embeddings / sum_mask\n",
    "    \n",
    "    def forward(self, sentences, task='A'):\n",
    "        \"\"\"Forward pass with multi-task support.\"\"\"\n",
    "        # Tokenize input sentences\n",
    "        encoded_input = self.tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "        \n",
    "        # Get transformer output\n",
    "        model_output = self.transformer(**encoded_input)\n",
    "        \n",
    "        # Perform mean pooling to get sentence embeddings\n",
    "        sentence_embeddings = self.mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "        \n",
    "        # Route to the task-specific head\n",
    "        if task == 'A':  # Task A: Sentence Classification\n",
    "            logits = self.classification_head_A(sentence_embeddings)\n",
    "            probs = F.softmax(logits, dim=-1)  # Apply softmax for sentence classification output\n",
    "            \n",
    "            # Convert logits to sentence classification labels (predictions)\n",
    "            sentence_predictions = torch.argmax(probs, dim=-1)  # Get the index of the highest probability class\n",
    "            sentence_labels = [self.sentence_classification_labels[idx.item()] for idx in sentence_predictions]\n",
    "            \n",
    "            return sentence_labels, probs  # Return both labels and probabilities\n",
    "\n",
    "        elif task == 'B':  # Task B: Sentiment Analysis\n",
    "            logits = self.classification_head_B(sentence_embeddings)\n",
    "            probs = F.softmax(logits, dim=-1)  # Apply softmax for sentiment analysis output\n",
    "            \n",
    "            # Convert logits to sentiment labels (predictions)\n",
    "            sentiment_predictions = torch.argmax(probs, dim=-1)  # Get the index of the highest probability class\n",
    "            sentiment_labels = [self.sentiment_labels[idx.item()] for idx in sentiment_predictions]\n",
    "            \n",
    "            return sentiment_labels, probs  # Return both labels and probabilities\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown task: {task}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model object\n",
    "model = MultiTaskSentenceTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example sentences for sentence classification and sentiment analysis\n",
    "sentences = [\"I love this product!\", \"I hate waiting in line.\", \"It's an average experience.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Classification Results:\n",
      "Sentence: I love this product!\n",
      "Predicted Label: class_2\n",
      "Probabilities: tensor([0.3419, 0.3518, 0.3063], grad_fn=<UnbindBackward0>)\n",
      "\n",
      "Sentence: I hate waiting in line.\n",
      "Predicted Label: class_1\n",
      "Probabilities: tensor([0.3656, 0.3081, 0.3263], grad_fn=<UnbindBackward0>)\n",
      "\n",
      "Sentence: It's an average experience.\n",
      "Predicted Label: class_3\n",
      "Probabilities: tensor([0.2968, 0.3344, 0.3687], grad_fn=<UnbindBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Forward pass for Task A (Sentence Classification)\n",
    "sentence_labels, sentence_probs = model(sentences, task='A')\n",
    "print(\"Sentence Classification Results:\")\n",
    "for sentence, label, prob in zip(sentences, sentence_labels, sentence_probs):\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Predicted Label: {label}\")\n",
    "    print(f\"Probabilities: {prob}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis Results:\n",
      "Sentence: I love this product!\n",
      "Predicted Sentiment: neutral\n",
      "Probabilities: tensor([0.2973, 0.3906, 0.3121], grad_fn=<UnbindBackward0>)\n",
      "\n",
      "Sentence: I hate waiting in line.\n",
      "Predicted Sentiment: positive\n",
      "Probabilities: tensor([0.3248, 0.3305, 0.3448], grad_fn=<UnbindBackward0>)\n",
      "\n",
      "Sentence: It's an average experience.\n",
      "Predicted Sentiment: neutral\n",
      "Probabilities: tensor([0.3183, 0.3684, 0.3133], grad_fn=<UnbindBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Forward pass for Task B (Sentiment Analysis)\n",
    "sentiment_labels, sentiment_probs = model(sentences, task='B')\n",
    "print(\"Sentiment Analysis Results:\")\n",
    "for sentence, label, prob in zip(sentences, sentiment_labels, sentiment_probs):\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Predicted Sentiment: {label}\")\n",
    "    print(f\"Probabilities: {prob}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlfetch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
